import argparse
import os
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

class Options():
    def __init__(self):
        self.parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
        self.initialize_parser()

    def add_optim_options(self):
        self.parser.add_argument('--warmup_steps', type=int, default=1000)
        self.parser.add_argument('--total_steps', type=int, default=1000)
        self.parser.add_argument('--scheduler_steps', type=int, default=None, 
                        help='total number of step for the scheduler, if None then scheduler_total_step = total_step')
        self.parser.add_argument('--accumulation_steps', type=int, default=1)
        self.parser.add_argument('--dropout', type=float, default=0.1, help='dropout rate')
        self.parser.add_argument('--classifier_dropout', type=float, default=0.1, help='dropout rate for classifier')
        self.parser.add_argument('--lr', type=float, default=1e-4, help='learning rate')
        self.parser.add_argument('--clip', type=float, default=1., help='gradient clipping')
        self.parser.add_argument('--optim', type=str, default='adam')
        self.parser.add_argument('--scheduler', type=str, default='fixed')
        self.parser.add_argument('--weight_decay', type=float, default=0.1)
        self.parser.add_argument('--fixed_lr', action='store_true')


    def add_eval_options(self):
        self.parser.add_argument('--write_results', action='store_true', help='save results')
        self.parser.add_argument('--write_crossattention_scores', action='store_true', 
                        help='save dataset with cross-attention scores')

    def add_t5_options(self):
        self.parser.add_argument('--train_data', type=str, default='none', help='path of train data')
        self.parser.add_argument('--eval_data', type=str, default='none', help='path of eval data')
        self.parser.add_argument('--model_size', type=str, default='base')
        self.parser.add_argument('--use_checkpoint', action='store_true', help='use checkpoint in the encoder')
        self.parser.add_argument('--text_maxlength', type=int, default=200, 
                        help='maximum number of tokens in text segments (question+passage)')
        self.parser.add_argument('--answer_maxlength', type=int, default=20,
                        help='maximum number of tokens used to train the model, no truncation if -1')
        self.parser.add_argument('--no_title', action='store_true', 
                        help='article titles not included in passages')

        self.parser.add_argument('--add_loss', type=str, default=None)
        self.parser.add_argument('--add_type_emb', action='store_true')
        self.parser.add_argument('--cat_emb', action='store_true')
        self.parser.add_argument('--rerank', action='store_true')
        self.parser.add_argument('--sample_pos_neg', action='store_true')
        self.parser.add_argument('--extra_decoder_inputs', action='store_true')
        self.parser.add_argument('--change_golden', action='store_true',
                                 help='change label 0 to 10000, label 1 to 0 in golden')
        self.parser.add_argument('--split_psg_subset', action='store_true', help='')
        self.parser.add_argument('--sum_golden_cross_att', action='store_true', help='')
        self.parser.add_argument('--output_attentions', action='store_true', help='output attentions in decoder')

        self.parser.add_argument('--n_context', type=int, default=1, help='the number of the snippets we feed to fid')
        self.parser.add_argument('--beam_size', type=int, default=1,
                                 help='if we need to use beam search, what beam size is used here?')
        self.parser.add_argument('--use_adapted_model', action='store_true')
        self.parser.add_argument('--adapted_model_path', type=str, help='the path to the adapted codet5 model')



    def initialize_parser(self):

        self.parser.add_argument('--name', type=str, default='experiment_name', help='name of the experiment')
        self.parser.add_argument('--checkpoint_dir', type=str, default='./checkpoint/', help='models are saved here')
        self.parser.add_argument('--model_path', type=str, default='none', help='path for retraining')
        self.parser.add_argument('--no_wandb', action='store_true', help='not to use wandb')

        self.parser.add_argument("--per_gpu_train_batch_size", default=1, type=int,
                        help="Batch size per GPU/CPU for training.")
        self.parser.add_argument("--per_gpu_eval_batch_size", default=1, type=int,
                                 help="Batch size per GPU/CPU for evaluating.")
        self.parser.add_argument('--maxload', type=int, default=-1)

        self.parser.add_argument("--local_rank", type=int, default=-1,
                        help="For distributed training: local_rank")
        self.parser.add_argument('--cpu', action='store_true')
        self.parser.add_argument("--main_port", type=int, default=0,
                        help="Main port (for multi-node SLURM jobs)")
        self.parser.add_argument('--seed', type=int, default=4, help="random seed for initialization")
        # training parameters
        self.parser.add_argument('--eval_freq', type=int, default=500,
                        help='evaluate model every <eval_freq> steps during training')
        self.parser.add_argument('--save_freq', type=int, default=5000,
                        help='save model every <save_freq> steps during training')
        self.parser.add_argument('--eval_print_freq', type=int, default=1000,
                        help='print intermdiate results of evaluation every <eval_print_freq> steps')

        # Unlimiformer
        self.parser.add_argument('--layer_begin', type=int, default=0,
                                 help='The layer to begin applying KNN. Default is 0.')
        self.parser.add_argument('--layer_end', type=int, default=None,
                                 help='The layer to end applying KNN. Default is None, meaning until the last layer.')
        self.parser.add_argument('--chunk_overlap', type=float, default=0.5,
                                 help='The fraction of overlap between input chunks for long sequences.')
        self.parser.add_argument('--chunk_size', type=int, default=1024,
                                 help='The size of each input chunk for long sequences.')
        self.parser.add_argument('--use_datastore', type=bool, default=True,
                                 help='Whether to use a datastore for retrieval. Default is True.')
        self.parser.add_argument('--gpu_index', type=bool, default=True,
                                 help='Whether to use GPU index for retrieval. Default is True.')
        self.parser.add_argument('--unlimiformer_training', type=bool, default=False,
                                 help='Whether to train with Unlimiformer. Default is False.')
        self.parser.add_argument('--flat_index', type=bool, default=False,
                                 help='Whether to use a flat index for KNN. Default is False.')
        self.parser.add_argument('--test_unlimiformer', type=bool, default=False,
                                 help='Whether to test Unlimiformer. Default is False.')
        self.parser.add_argument('--test_datastore', type=bool, default=False,
                                 help='Whether to test datastore retrieval. Default is False.')
        self.parser.add_argument('--reconstruct_embeddings', type=bool, default=False,
                                 help='Whether to reconstruct embeddings. Default is False.')
        self.parser.add_argument('--unlimiformer_exclude', type=bool, default=False,
                                 help='Whether to exclude the attention in the standard window for Unlimiformer. Default is False.')
        self.parser.add_argument('--unlimiformer_verbose', type=bool, default=False,
                                 help='Whether to print verbose output during Unlimiformer execution. Default is False.')


    def print_options(self, opt):
        message = '\n'
        for k, v in sorted(vars(opt).items()):
            comment = ''
            default_value = self.parser.get_default(k)
            if v != default_value:
                comment = f'\t(default: {default_value})'
            message += f'{str(k):>30}: {str(v):<40}{comment}\n'

        expr_dir = Path(opt.checkpoint_dir)/ opt.name
        model_dir = expr_dir / 'models'
        model_dir.mkdir(parents=True, exist_ok=True)
        with open(expr_dir/'opt.log', 'wt') as opt_file:
            opt_file.write(message)
            opt_file.write('\n')

        logger.info(message)
    def parse(self):
        opt = self.parser.parse_args()
        return opt



def get_options(use_reader=False,
                use_retriever=False,
                use_optim=False,
                use_eval=False):
    options = Options()
    if use_reader:
        options.add_fid_options()
    # if use_retriever:
    #     options.add_retriever_options()
    if use_optim:
        options.add_optim_options()
    if use_eval:
        options.add_eval_options()
    return options.parse()
